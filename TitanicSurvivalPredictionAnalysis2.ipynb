{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45905b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c639008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('train (1).csv')\n",
    "test_data = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f961e4",
   "metadata": {},
   "source": [
    "Training Data: Contains features such as Passenger ID, Survival status (0 = No, 1 = Yes), Passenger class (Pclass), Name, Sex, Age, Number of siblings/spouses aboard (SibSp), Number of parents/children aboard (Parch), Ticket number, Fare, Cabin number, and Embarkation port.\n",
    "Test Data: Has the same features as the training data, except for the Survival status, which is what we aim to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272bf7b",
   "metadata": {},
   "source": [
    "1 . Data Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "481d4456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   PassengerId  Survived  Pclass  \\\n",
       " 0            1         0       3   \n",
       " 1            2         1       1   \n",
       " 2            3         1       3   \n",
       " 3            4         1       1   \n",
       " 4            5         0       3   \n",
       " \n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       " 0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       " 1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       " 2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       " 3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       " 4                           Allen, Mr. William Henry    male  35.0      0   \n",
       " \n",
       "    Parch            Ticket     Fare Cabin Embarked  \n",
       " 0      0         A/5 21171   7.2500   NaN        S  \n",
       " 1      0          PC 17599  71.2833   C85        C  \n",
       " 2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       " 3      0            113803  53.1000  C123        S  \n",
       " 4      0            373450   8.0500   NaN        S  ,\n",
       "    PassengerId  Pclass                                          Name     Sex  \\\n",
       " 0          892       3                              Kelly, Mr. James    male   \n",
       " 1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       " 2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       " 3          895       3                              Wirz, Mr. Albert    male   \n",
       " 4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       " \n",
       "     Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       " 0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       " 1  47.0      1      0   363272   7.0000   NaN        S  \n",
       " 2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       " 3  27.0      0      0   315154   8.6625   NaN        S  \n",
       " 4  22.0      1      1  3101298  12.2875   NaN        S  )"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of each dataset to understand their structure\n",
    "train_data_head = train_data.head()\n",
    "test_data_head = test_data.head()\n",
    "\n",
    "\n",
    "train_data_head, test_data_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90e1fb",
   "metadata": {},
   "source": [
    "Data Exploration Findings:\n",
    "Missing Values:\n",
    "\n",
    "Age: 177 missing values.\n",
    "Cabin: 687 missing values, which is a significant portion of the dataset.\n",
    "Embarked: 2 missing values.\n",
    "Numerical Feature Summary:\n",
    "\n",
    "Age: Ranges from 0.42 to 80 years. The distribution appears reasonable without obvious outliers.\n",
    "SibSp (Siblings/Spouses): Most passengers have 0 or 1 sibling/spouse aboard. The maximum is 8, which is high but plausible.\n",
    "Parch (Parents/Children): Similar to SibSp, most passengers have 0 parents/children aboard. The maximum is 6.\n",
    "Fare: Ranges from 0 to 512.33. The maximum fare is notably high, indicating a potential outlier or simply variation in ticket prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7267b3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PassengerId      0\n",
       " Survived         0\n",
       " Pclass           0\n",
       " Name             0\n",
       " Sex              0\n",
       " Age            177\n",
       " SibSp            0\n",
       " Parch            0\n",
       " Ticket           0\n",
       " Fare             0\n",
       " Cabin          687\n",
       " Embarked         2\n",
       " dtype: int64,\n",
       "        PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       " count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       " mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       " std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       " min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       " 25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       " 50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       " 75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       " max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       " \n",
       "             Parch        Fare  \n",
       " count  891.000000  891.000000  \n",
       " mean     0.381594   32.204208  \n",
       " std      0.806057   49.693429  \n",
       " min      0.000000    0.000000  \n",
       " 25%      0.000000    7.910400  \n",
       " 50%      0.000000   14.454200  \n",
       " 75%      0.000000   31.000000  \n",
       " max      6.000000  512.329200  )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in the training data\n",
    "missing_values_train = train_data.isnull().sum()\n",
    "\n",
    "# Summary statistics for numerical features to identify outliers\n",
    "numerical_summary_train = train_data.describe()\n",
    "\n",
    "missing_values_train, numerical_summary_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72621e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1754240165.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    2. Data Preprocessing:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "2. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d35e6ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>CabinAssigned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex_female Sex_male Embarked_C Embarked_Q Embarked_S PassengerId Survived  \\\n",
       "0        0.0      1.0        0.0        0.0        1.0           1        0   \n",
       "1        1.0      0.0        1.0        0.0        0.0           2        1   \n",
       "2        1.0      0.0        0.0        0.0        1.0           3        1   \n",
       "3        1.0      0.0        0.0        0.0        1.0           4        1   \n",
       "4        0.0      1.0        0.0        0.0        1.0           5        0   \n",
       "\n",
       "  Pclass                                               Name   Age SibSp Parch  \\\n",
       "0      3                            Braund, Mr. Owen Harris  22.0     1     0   \n",
       "1      1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0     1     0   \n",
       "2      3                             Heikkinen, Miss. Laina  26.0     0     0   \n",
       "3      1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0     1     0   \n",
       "4      3                           Allen, Mr. William Henry  35.0     0     0   \n",
       "\n",
       "             Ticket     Fare Cabin CabinAssigned  \n",
       "0         A/5 21171     7.25   NaN             0  \n",
       "1          PC 17599  71.2833   C85             1  \n",
       "2  STON/O2. 3101282    7.925   NaN             0  \n",
       "3            113803     53.1  C123             1  \n",
       "4            373450     8.05   NaN             0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing values\n",
    "# For Age, use median to fill missing values\n",
    "# For Cabin, transform it into a binary feature indicating whether a cabin was assigned or not\n",
    "# For Embarked, fill missing values with the most common port\n",
    "\n",
    "# Filling missing Age values with median\n",
    "age_imputer = SimpleImputer(strategy='median')\n",
    "train_data['Age'] = age_imputer.fit_transform(train_data[['Age']])\n",
    "\n",
    "# Transforming Cabin into a binary feature\n",
    "train_data['CabinAssigned'] = train_data['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "test_data['CabinAssigned'] = test_data['Cabin'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "# Filling missing Embarked values with the most common port\n",
    "common_port = train_data['Embarked'].mode()[0]\n",
    "train_data['Embarked'].fillna(common_port, inplace=True)\n",
    "\n",
    "# Convert categorical variables into numerical format\n",
    "# Using One-Hot Encoding for Sex and Embarked\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Apply OneHotEncoder to training data\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', one_hot_encoder, categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "train_data_transformed = preprocessor.fit_transform(train_data)\n",
    "\n",
    "# Converting the transformed data back into a DataFrame for better readability\n",
    "# Getting the new column names from the one-hot encoder\n",
    "new_columns = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "new_columns = list(new_columns) + [col for col in train_data.columns if col not in categorical_features]\n",
    "\n",
    "# Creating the new DataFrame\n",
    "train_data_preprocessed = pd.DataFrame(train_data_transformed, columns=new_columns)\n",
    "\n",
    "# Checking the transformed data\n",
    "train_data_preprocessed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840a5aa",
   "metadata": {},
   "source": [
    "The data preprocessing is complete. Here's what was done:\n",
    "\n",
    "Missing Age values were filled with the median age.\n",
    "The Cabin feature was transformed into a binary feature CabinAssigned, indicating whether a cabin was assigned (1) or not (0).\n",
    "Missing Embarked values were filled with the most common port.\n",
    "Categorical variables (Sex, Embarked) were converted into numerical format using one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e1eb1",
   "metadata": {},
   "source": [
    "3. Model Building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e900f6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(max_iter=1000),\n",
       " DecisionTreeClassifier(random_state=42),\n",
       " RandomForestClassifier(random_state=42))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into features and target label\n",
    "X = train_data_preprocessed.drop(['Survived', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "y = train_data_preprocessed['Survived'].astype('int')\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building and training the models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree\n",
    "dec_tree = DecisionTreeClassifier(random_state=42)\n",
    "dec_tree.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rand_forest = RandomForestClassifier(random_state=42)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "\n",
    "# The models are now trained. Next, we'll evaluate their performance.\n",
    "(log_reg, dec_tree, rand_forest)  # Indicating that the models have been successfully created and trained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4362f",
   "metadata": {},
   "source": [
    "4. Model Evaluation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dab8201",
   "metadata": {},
   "source": [
    "Now, let's evaluate the performance of these models. We'll use metrics like accuracy, precision, recall, and F1-score to assess their performance on the validation set. This will help us understand how well each model is performing and guide us in choosing the best model for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38bb57dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.8212290502793296, 0.8, 0.7567567567567568, 0.7777777777777778),\n",
       " (0.7932960893854749,\n",
       "  0.7228915662650602,\n",
       "  0.8108108108108109,\n",
       "  0.7643312101910827),\n",
       " (0.8156424581005587,\n",
       "  0.7887323943661971,\n",
       "  0.7567567567567568,\n",
       "  0.7724137931034482))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate and return the performance metrics\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    # Making predictions on the validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Calculating the metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluating each model\n",
    "log_reg_metrics = evaluate_model(log_reg, X_val, y_val)\n",
    "dec_tree_metrics = evaluate_model(dec_tree, X_val, y_val)\n",
    "rand_forest_metrics = evaluate_model(rand_forest, X_val, y_val)\n",
    "\n",
    "log_reg_metrics, dec_tree_metrics, rand_forest_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c21f56",
   "metadata": {},
   "source": [
    "Model Evaluation Results\n",
    "The performance metrics for each model on the validation set are as follows:\n",
    "\n",
    "Logistic Regression:\n",
    "Accuracy: 82.12%\n",
    "Precision: 80.00%\n",
    "Recall: 75.68%\n",
    "F1-score: 77.78%\n",
    "\n",
    "Decision Tree:\n",
    "Accuracy: 79.33%\n",
    "Precision: 72.29%\n",
    "Recall: 81.08%\n",
    "F1-score: 76.43%\n",
    "\n",
    "Random Forest:\n",
    "Accuracy: 81.56%\n",
    "Precision: 78.87%\n",
    "Recall: 75.68%\n",
    "F1-score: 77.24%\n",
    "\n",
    "Observations:\n",
    "Logistic Regression shows the highest accuracy and precision among the three models. It has a balanced recall and precision, indicated by its F1-score.\n",
    "Decision Tree has a higher recall but lower precision and accuracy compared to the other models.\n",
    "Random Forest shows a good balance between precision and recall, with accuracy slightly lower than Logistic Regression but higher than the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa00e35",
   "metadata": {},
   "source": [
    "5. Model Tuning:\n",
    "- Experiment with hyperparameter tuning to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aadb5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IFEANYI\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "150 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\IFEANYI\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\IFEANYI\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\IFEANYI\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\IFEANYI\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\IFEANYI\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.81455727 0.81598542 0.81315867\n",
      " 0.82158968 0.81741357 0.81739387        nan        nan        nan\n",
      " 0.81877278 0.82723333 0.82159953 0.82018123 0.82160938 0.82301783\n",
      "        nan        nan        nan 0.81739387 0.81457697 0.81880232\n",
      " 0.81599527 0.82580518 0.82299813        nan        nan        nan\n",
      " 0.82301783 0.81880232 0.81879248 0.81321777 0.81879248 0.81317837\n",
      "        nan        nan        nan 0.81603467 0.81738402 0.81600512\n",
      " 0.81177977 0.81459667 0.82160938        nan        nan        nan\n",
      " 0.81595588 0.82298828 0.82018123 0.81316852 0.82300798 0.81314882\n",
      "        nan        nan        nan 0.82300798 0.81595588 0.82298828\n",
      " 0.82160938 0.81456712 0.82299813        nan        nan        nan\n",
      " 0.82300798 0.82723333 0.82582488 0.82723333 0.82159953 0.82157983\n",
      "        nan        nan        nan 0.81319807 0.82439673 0.81880232\n",
      " 0.82019108 0.82160938 0.81596572        nan        nan        nan\n",
      " 0.81878263 0.81741357 0.82582488 0.82162908 0.82441643 0.81879248]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "Tuned Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       105\n",
      "           1       0.80      0.70      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print('Best Parameters:', CV_rfc.best_params_)\n",
    "\n",
    "# Evaluating the tuned model\n",
    "print('Tuned Random Forest Classification Report:')\n",
    "print(classification_report(y_val, CV_rfc.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9827f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9b3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
